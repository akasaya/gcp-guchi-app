import os
import uuid
import subprocess
from google.cloud import aiplatform, storage

def get_gcloud_project():
    """gcloud configã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’å–å¾—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
    try:
        project_id_bytes = subprocess.check_output(
            ["gcloud", "config", "get-value", "project"],
            stderr=subprocess.PIPE
        )
        project_id = project_id_bytes.strip().decode("utf-8")
        # gcloudãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆ '(unset)' ãŒè¿”ã‚‹
        if project_id == "(unset)":
            return None
        return project_id
    except (subprocess.CalledProcessError, FileNotFoundError):
        return None

# --- è¨­å®šé …ç›® ---
# gcloud configã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’å–å¾—ã€‚è¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã€‚
PROJECT_ID = get_gcloud_project()
if not PROJECT_ID:
    raise ValueError(
        "GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        " 'gcloud config set project YOUR_PROJECT_ID' ã‚’å®Ÿè¡Œã—ã¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
    )

# ä½œæˆã™ã‚‹ãƒªã‚½ãƒ¼ã‚¹ã®ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã¨è¡¨ç¤ºå
REGION = "asia-northeast1" # æ±äº¬ãƒªãƒ¼ã‚¸ãƒ§ãƒ³
INDEX_DISPLAY_NAME = "guchiswipe-node-index"
ENDPOINT_DISPLAY_NAME = "guchiswipe-node-endpoint"
# ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹éš›ã®ID
DEPLOYED_INDEX_ID_PREFIX = "guchiswipe_deployed"

# ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®GCSãƒã‚±ãƒƒãƒˆï¼ˆIndexä½œæˆã«å¿…è¦ï¼‰
BUCKET_NAME = f"{PROJECT_ID}-guchiswipe-vs-store"
BUCKET_URI = f"gs://{BUCKET_NAME}"

# ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•° (text-multilingual-embedding-002 ã¯ 768æ¬¡å…ƒ)
DIMENSIONS = 768
# --- è¨­å®šé …ç›®ã“ã“ã¾ã§ ---

def setup_vector_search():
    """Vertex AI Vector Search ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½œæˆãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹"""
    print(f"Project: {PROJECT_ID}, Region: {REGION}")

    # GCSãƒã‚±ãƒƒãƒˆã®å­˜åœ¨ç¢ºèªã¨ä½œæˆ
    storage_client = storage.Client(project=PROJECT_ID)
    bucket = storage_client.lookup_bucket(BUCKET_NAME)
    if bucket is None:
        print(f"Creating GCS bucket: {BUCKET_NAME}...")
        storage_client.create_bucket(BUCKET_NAME, location=REGION)
        print("âœ… Bucket created.")
    else:
        print(f"Bucket {BUCKET_NAME} already exists.")
        
    aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)

    # 1. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆ
    print(f"\n--- 1. Checking/Creating Index: {INDEX_DISPLAY_NAME} ---")
    existing_indexes = aiplatform.MatchingEngineIndex.list(
        filter=f'display_name="{INDEX_DISPLAY_NAME}"'
    )
    if existing_indexes:
        index = existing_indexes[0]
        print(f"âœ… Index already exists: {index.resource_name}")
    else:
        print("Creating new index...")
        index = aiplatform.MatchingEngineIndex.create_tree_ah_index(
            display_name=INDEX_DISPLAY_NAME,
            dimensions=DIMENSIONS,
            approximate_neighbors_count=10,
            distance_measure_type="DOT_PRODUCT_DISTANCE",
            index_update_method="STREAM_UPDATE", # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ç”¨
            description="Index for GuchiSwipe user conversation nodes."
        )
        print(f"âœ… Index created successfully: {index.resource_name}")

    # 2. ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ
    print(f"\n--- 2. Checking/Creating Endpoint: {ENDPOINT_DISPLAY_NAME} ---")
    existing_endpoints = aiplatform.MatchingEngineIndexEndpoint.list(
        filter=f'display_name="{ENDPOINT_DISPLAY_NAME}"'
    )
    if existing_endpoints:
        endpoint = existing_endpoints[0]
        print(f"âœ… Endpoint already exists: {endpoint.resource_name}")
    else:
        print("Creating new endpoint...")
        endpoint = aiplatform.MatchingEngineIndexEndpoint.create(
            display_name=ENDPOINT_DISPLAY_NAME,
            public_endpoint_enabled=True,
            description="Endpoint for GuchiSwipe node index."
        )
        print(f"âœ… Endpoint created successfully: {endpoint.resource_name}")

    # 3. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ãƒ‡ãƒ—ãƒ­ã‚¤
    print(f"\n--- 3. Checking/Deploying Index to Endpoint ---")
    # ã™ã§ã«åŒã˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    deployed_index_id_obj = next(
        (d for d in endpoint.deployed_indexes if d.index == index.resource_name), 
        None
    )

    if deployed_index_id_obj:
        deployed_id = deployed_index_id_obj.id
        print(f"âœ… Index '{index.display_name}' is already deployed to endpoint '{endpoint.display_name}' with Deployed ID: {deployed_id}.")
    else:
        # ãƒ‡ãƒ—ãƒ­ã‚¤IDã¯ãƒ¦ãƒ‹ãƒ¼ã‚¯ã«ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        deployed_id = f"{DEPLOYED_INDEX_ID_PREFIX}_{str(uuid.uuid4())[:8]}"
        print(f"Deploying index with Deployed ID: {deployed_id}... (This may take up to 30 minutes)")
        endpoint.deploy_index(
            index=index,
            deployed_index_id=deployed_id
        )
        print(f"âœ… Index deployed successfully.")

    # 4. å¿…è¦ãªæƒ…å ±ã‚’å‡ºåŠ›
    print("\n--- ğŸš€ Setup Complete! ---")
    print("Please set the following environment variables in your Cloud Run service:")
    print("-" * 60)
    print(f"VECTOR_SEARCH_INDEX_ID={index.name}")
    print(f"VECTOR_SEARCH_ENDPOINT_ID={endpoint.name}")
    print(f"VECTOR_SEARCH_DEPLOYED_INDEX_ID={deployed_id}")
    print(f"GCP_VERTEX_AI_REGION={REGION}")
    print("-" * 60)

if __name__ == "__main__":
    setup_vector_search()
