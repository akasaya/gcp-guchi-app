import firebase_admin
from firebase_admin import credentials, firestore, auth
from flask import Flask, request, jsonify
from flask_cors import CORS

import os
import json
import re
import traceback
import threading

from tenacity import retry, stop_after_attempt, wait_exponential
import vertexai
from vertexai.generative_models import GenerativeModel, GenerationConfig

# --- GCP & Firebase åˆæœŸåŒ– ---
try:
    print("Initializing GCP services using Application Default Credentials...")
    firebase_admin.initialize_app()
    db_firestore = firestore.client()
    
    app_instance = firebase_admin.get_app()
    project_id = app_instance.project_id
    print(f"âœ… Firebase Admin SDK initialized for project: {project_id}")

    vertex_ai_region = os.getenv('GCP_VERTEX_AI_REGION', 'us-central1')
    vertexai.init(project=project_id, location=vertex_ai_region)
    print(f"âœ… Vertex AI initialized for project: {project_id} in {vertex_ai_region}")

except Exception as e:
    db_firestore = None
    print(f"âŒ Error during initialization: {e}")
    traceback.print_exc()
    if 'K_SERVICE' in os.environ:
        raise

app = Flask(__name__)
# --- CORSè¨­å®š ---
prod_origin = "https://guchi-app-flutter.web.app"
if 'K_SERVICE' in os.environ:
    origins = [prod_origin]
else:
    origins = [
        prod_origin,
        re.compile(r"http://localhost:.*"),
        re.compile(r"http://127.0.0.1:.*"),
    ]
CORS(app, resources={r"/*": {"origins": origins}})

# ===== JSONã‚¹ã‚­ãƒ¼ãƒå®šç¾© =====
QUESTIONS_SCHEMA = {
    "type": "object",
    "properties": {
        "questions": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {"question_text": {"type": "string"}},
                "required": ["question_text"]
            }
        }
    },
    "required": ["questions"]
}

# ã€å¾©æ´»ã€‘è¦ç´„ç”Ÿæˆå°‚ç”¨ã®ã‚¹ã‚­ãƒ¼ãƒ
SUMMARY_SCHEMA = {
    "type": "object",
    "properties": {
        "title": {"type": "string", "description": "ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã‚’è¦ç´„ã™ã‚‹15æ–‡å­—ç¨‹åº¦ã®çŸ­ã„ã‚¿ã‚¤ãƒˆãƒ«"},
        "insights": {"type": "string", "description": "æŒ‡å®šã•ã‚ŒãŸMarkdownå½¢å¼ã§ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿ƒç†åˆ†æãƒ¬ãƒãƒ¼ãƒˆ"}
    },
    "required": ["title", "insights"]
}

GRAPH_SCHEMA = {
    "type": "object",
    "properties": {
        "nodes": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "id": {"type": "string"},
                    "type": {"type": "string", "enum": ["emotion", "topic", "keyword", "issue"]},
                    "size": {"type": "integer"}
                },
                "required": ["id", "type", "size"]
            }
        },
        "edges": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "source": {"type": "string"},
                    "target": {"type": "string"},
                    "weight": {"type": "integer"}
                },
                "required": ["source", "target", "weight"]
            }
        }
    },
    "required": ["nodes", "edges"]
}

# ===== ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ =====

# ã€æ”¹å–„ç‰ˆã€‘è¦ç´„ç”Ÿæˆå°‚ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
SUMMARY_ONLY_PROMPT_TEMPLATE = """
ã‚ãªãŸã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…ã®å‹•ãã‚’åˆ†æã™ã‚‹ãƒ—ãƒ­ã®è‡¨åºŠå¿ƒç†å£«ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€Œ{topic}ã€ã¨ã„ã†ãƒ†ãƒ¼ãƒã«ã¤ã„ã¦å¯¾è©±ã—ã¦ã„ã¾ã™ã€‚
ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ä¼šè©±å±¥æ­´ã‚’åˆ†æã—ã€å¿…ãšæŒ‡ç¤ºé€šã‚Šã®JSONå½¢å¼ã§åˆ†æãƒ¬ãƒãƒ¼ãƒˆã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

# åˆ†æå¯¾è±¡ã®ä¼šè©±å±¥æ­´
{swipes_text}

# å‡ºåŠ›å½¢å¼ (JSON)
å¿…ãšä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’æŒã¤JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
- `title`: ä¼šè©±å…¨ä½“ã‚’è±¡å¾´ã™ã‚‹15æ–‡å­—ç¨‹åº¦ã®çŸ­ã„ã‚¿ã‚¤ãƒˆãƒ«ã€‚
- `insights`: ä»¥ä¸‹ã®Markdownå½¢å¼ã§ **å³å¯†ã«** è¨˜è¿°ã•ã‚ŒãŸåˆ†æãƒ¬ãƒãƒ¼ãƒˆã€‚

```markdown
### âœ¨ å…¨ä½“çš„ãªè¦ç´„
ï¼ˆã“ã“ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç¾åœ¨ã®å¿ƒç†çŠ¶æ…‹ã€ä¸»ãªæ„Ÿæƒ…ã€å†…é¢çš„ãªè‘›è—¤ãªã©ã‚’2ã€œ3æ–‡ã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ï¼‰

### ğŸ“ è©³ç´°ãªåˆ†æ
ï¼ˆã“ã“ã«ã€å…·ä½“çš„ãªåˆ†æå†…å®¹ã‚’ç®‡æ¡æ›¸ãã§è¨˜è¿°ã—ã¦ãã ã•ã„ï¼‰
* **æ„Ÿæƒ…ã®çŠ¶æ…‹**: ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ„Ÿã˜ã¦ã„ã‚‹ä¸»è¦ãªæ„Ÿæƒ…ã«ã¤ã„ã¦ã€ãã®æ ¹æ‹ ã¨å…±ã«è¨˜è¿°ã—ã¦ãã ã•ã„ï¼‰
* **æ³¨ç›®ã™ã¹ãç‚¹**: ï¼ˆå›ç­”å†…å®¹ã¨ã€ãŸã‚ã‚‰ã„æ™‚é–“ã‹ã‚‰æ¨æ¸¬ã•ã‚Œã‚‹æ„Ÿæƒ…ã®çŸ›ç›¾ã€ç‰¹ã«å°è±¡çš„ãªå›ç­”ãªã©ã€åˆ†æã®éµã¨ãªã£ãŸãƒã‚¤ãƒ³ãƒˆã‚’å…·ä½“çš„ã«æŒ™ã’ã¦ãã ã•ã„ã€‚ä¼šè©±å±¥æ­´ã«ã€Œç‰¹ã«è¿·ã„ãŒè¦‹ã‚‰ã‚Œã¾ã—ãŸã€ã¨è¨˜è¼‰ã®ã‚ã‚‹å›ç­”ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãŸã‚ã‚‰ã„ã‚„è‘›è—¤ã‚’æŠ±ãˆã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰
* **æ ¹æœ¬çš„ãªèª²é¡Œ**: ï¼ˆåˆ†æã‹ã‚‰æ¨æ¸¬ã•ã‚Œã‚‹ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç›´é¢ã—ã¦ã„ã‚‹æ ¹æœ¬çš„ãªèª²é¡Œã‚„æ¬²æ±‚ã«ã¤ã„ã¦è¨˜è¿°ã—ã¦ãã ã•ã„ï¼‰

### ğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸ã®ææ¡ˆ
ï¼ˆä»Šå›ã®åˆ†æã‚’è¸ã¾ãˆã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¬¡å›ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§æ·±æ˜ã‚Šã™ã‚‹ã¨è‰¯ã•ãã†ãªãƒ†ãƒ¼ãƒã‚„ã€æ—¥å¸¸ç”Ÿæ´»ã§æ„è­˜ã—ã¦ã¿ã‚‹ã¨è‰¯ã„ã“ã¨ãªã©ã‚’ã€å…·ä½“çš„ã‹ã¤ãƒã‚¸ãƒ†ã‚£ãƒ–ãªè¨€è‘‰ã§ææ¡ˆã—ã¦ãã ã•ã„ï¼‰
```
"""


GRAPH_ANALYSIS_PROMPT_TEMPLATE = """
ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã§ã‚ã‚Šã€è‡¨åºŠå¿ƒç†å£«ã§ã‚‚ã‚ã‚Šã¾ã™ã€‚
ã“ã‚Œã‹ã‚‰æ¸¡ã™ãƒ†ã‚­ã‚¹ãƒˆã¯ã€ã‚ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¤‡æ•°å›ã®ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆã‚³ã‚³ãƒ­ãƒ’ãƒ¢ãƒˆã‚¯ï¼‰ã®è¨˜éŒ²ã§ã™ã€‚
ã“ã®è¨˜éŒ²å…¨ä½“ã‚’åˆ†æã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿ƒç†çŠ¶æ…‹ã®æ ¸ã¨ãªã‚‹è¦ç´ ï¼ˆæ„Ÿæƒ…ã€æ‚©ã¿ã€ãƒˆãƒ”ãƒƒã‚¯ã€é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼‰ã‚’æŠ½å‡ºã—ã€ãã‚Œã‚‰ã®é–¢é€£æ€§ã‚’è¡¨ç¾ã™ã‚‹ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
å‡ºåŠ›ã¯ã€ä»¥ä¸‹ã®ä»•æ§˜ã«å³å¯†ã«å¾“ã£ãŸJSONå½¢å¼ã®ã¿ã¨ã—ã¦ãã ã•ã„ã€‚èª¬æ˜ã‚„å‰ç½®ãã¯ä¸€åˆ‡ä¸è¦ã§ã™ã€‚
ã€å‡ºåŠ›JSONã®ä»•æ§˜ã€‘
â˜…â˜…â˜…é‡è¦: `id` ã¯å¿…ãšæ—¥æœ¬èªã®å˜èªã¾ãŸã¯çŸ­ã„ãƒ•ãƒ¬ãƒ¼ã‚ºã«ã—ã¦ãã ã•ã„ã€‚ãƒ­ãƒ¼ãƒå­—ã‚„è‹±èªã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚â˜…â˜…â˜…
{ "nodes": [ ... ], "edges": [ ... ] }
ã€åˆ†æã®ãƒ’ãƒ³ãƒˆã€‘
...
ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨˜éŒ²ã€‘
"""

CHAT_PROMPT_TEMPLATE = """
ã‚ãªãŸã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿ƒç†åˆ†æã®å°‚é–€å®¶ã§ã‚ã‚Šã€å…±æ„ŸåŠ›ã¨æ´å¯ŸåŠ›ã«å„ªã‚ŒãŸã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã§ã™ã€‚
...
"""

# ===== Gemini ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤ =====
@retry(wait=wait_exponential(multiplier=1, min=2, max=10), stop=stop_after_attempt(3))
def _call_gemini_with_schema(prompt: str, schema: dict, model_name: str) -> dict:
    model = GenerativeModel(model_name)
    attempt_num = _call_gemini_with_schema.retry.statistics.get('attempt_number', 1)
    print(f"--- Calling Gemini ({model_name}) with schema (Attempt: {attempt_num}) ---")
    response_text = ""
    try:
        response = model.generate_content(prompt, generation_config=GenerationConfig(response_mime_type="application/json", response_schema=schema))
        response_text = response.text
        json_start = response_text.find('{')
        json_end = response_text.rfind('}')
        if json_start != -1 and json_end != -1 and json_end > json_start:
            return json.loads(response_text[json_start:json_end+1])
        return json.loads(response_text)
    except Exception as e:
        print(f"Error on attempt {attempt_num} with model {model_name}: {e}\n--- Gemini Response ---\n{response_text if response_text else 'Empty'}\n---")
        traceback.print_exc()
        raise

def generate_initial_questions(topic):
    prompt = f"ã‚ãªãŸã¯ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã§ã™ã€‚ãƒˆãƒ”ãƒƒã‚¯ã€Œ{topic}ã€ã«ã¤ã„ã¦ã€ã€Œã¯ã„ã€ã‹ã€Œã„ã„ãˆã€ã§ç­”ãˆã‚‰ã‚Œã‚‹è³ªå•ã‚’5ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    try:
        flash_model = os.getenv('GEMINI_FLASH_NAME', 'gemini-1.5-flash-preview-05-20')
        data = _call_gemini_with_schema(prompt, QUESTIONS_SCHEMA, model_name=flash_model)
        return data.get("questions", [])
    except Exception as e:
        print(f"Failed to generate initial questions: {e}")
        return [{"question_text": "æœ€è¿‘ã€ç‰¹ã«ã‚¹ãƒˆãƒ¬ã‚¹ã‚’æ„Ÿã˜ã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"}] # Fallback

# ã€å¾©æ´»ã€‘æ·±æ˜ã‚Šè³ªå•ã‚’ç”Ÿæˆã™ã‚‹å°‚ç”¨ã®é–¢æ•°
def generate_follow_up_questions(insights):
    prompt = f"""
ã‚ãªãŸã¯ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®åˆ†æçµæœã‚’ã•ã‚‰ã«æ·±ã‚ã‚‹ã€ã€Œã¯ã„ã€ã‹ã€Œã„ã„ãˆã€ã§ç­”ãˆã‚‰ã‚Œã‚‹è³ªå•ã‚’5ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
# åˆ†æçµæœ
{insights}
"""
    flash_model = os.getenv('GEMINI_FLASH_NAME', 'gemini-1.5-flash-preview-05-20')
    data = _call_gemini_with_schema(prompt, QUESTIONS_SCHEMA, model_name=flash_model)
    return data.get("questions", [])

# ã€å¾©æ´»ã€‘è¦ç´„ã¨ã‚¿ã‚¤ãƒˆãƒ«ã®ã¿ã‚’ç”Ÿæˆã™ã‚‹é«˜é€Ÿãªé–¢æ•°
def generate_summary_only(topic, swipes_text):
    prompt = SUMMARY_ONLY_PROMPT_TEMPLATE.format(topic=topic, swipes_text=swipes_text)
    flash_model = os.getenv('GEMINI_FLASH_NAME', 'gemini-1.5-flash-preview-05-20')
    return _call_gemini_with_schema(prompt, SUMMARY_SCHEMA, model_name=flash_model)

def generate_graph_data(all_insights_text):
    prompt = GRAPH_ANALYSIS_PROMPT_TEMPLATE + all_insights_text
    pro_model = os.getenv('GEMINI_PRO_NAME', 'gemini-1.5-pro-preview-05-20')
    return _call_gemini_with_schema(prompt, GRAPH_SCHEMA, model_name=pro_model)

def generate_chat_response(session_summary, chat_history, user_message):
    history_str = "\n".join([f"{msg['author']}: {msg['text']}" for msg in chat_history])
    prompt = CHAT_PROMPT_TEMPLATE.format(session_summary=session_summary, chat_history=history_str, user_message=user_message)
    pro_model = os.getenv('GEMINI_PRO_NAME', 'gemini-1.5-pro-preview-05-20')
    model = GenerativeModel(pro_model)
    response = model.generate_content(prompt)
    return response.text.strip()

# --- ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç† ---

# ã€æ–°è¦è¿½åŠ ã€‘æ¬¡ã®è³ªå•ã‚’è£å´ã§ç”Ÿæˆã—ã€Firestoreã«ä¿å­˜ã™ã‚‹é–¢æ•°
def _prefetch_questions_and_save(session_id: str, user_id: str, insights_md: str, current_turn: int, max_turns: int):
    print(f"--- Triggered question prefetch for user: {user_id}, session: {session_id}, next_turn: {current_turn + 1} ---")
    if current_turn >= max_turns:
        print("Max turns reached. Skipping question prefetch.")
        return
    try:
        questions = generate_follow_up_questions(insights=insights_md)
        if not questions:
            print(f"âš ï¸ AI failed to generate prefetch questions for session {session_id}.")
            return

        session_doc_ref = db_firestore.collection('users').document(user_id).collection('sessions').document(session_id)
        next_turn = current_turn + 1
        questions_collection = session_doc_ref.collection('questions')
        
        last_question_query = questions_collection.order_by('order', direction=firestore.Query.DESCENDING).limit(1).stream()
        last_order = next(last_question_query, None)
        start_order = last_order.to_dict().get('order', -1) + 1 if last_order else 0

        batch = db_firestore.batch()
        count = 0
        for i, q_data in enumerate(questions):
            if q_text := q_data.get("question_text"):
                q_doc_ref = questions_collection.document()
                batch.set(q_doc_ref, {'text': q_text, 'turn': next_turn, 'order': start_order + i, 'created_at': firestore.SERVER_TIMESTAMP, 'is_prefetched': True})
                count += 1
        batch.commit()
        print(f"âœ… Successfully prefetched and saved {count} questions for turn {next_turn}.")
    except Exception as e:
        print(f"âŒ Failed to prefetch questions for session {session_id}: {e}")
        traceback.print_exc()

def _update_graph_cache(user_id: str):
    print(f"--- Triggered graph cache update for user: {user_id} ---")
    try:
        all_insights_text = _get_all_insights_as_text(user_id)
        if not all_insights_text: return
        
        raw_graph_data = generate_graph_data(all_insights_text)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚µãƒ‹ã‚¿ã‚¤ã‚º
        nodes = raw_graph_data.get('nodes', [])
        edges = raw_graph_data.get('edges', [])
        sanitized_nodes = [n for n in nodes if isinstance(n, dict) and n.get('id')]
        valid_node_ids = {n['id'] for n in sanitized_nodes}
        sanitized_edges = [e for e in edges if isinstance(e, dict) and e.get('source') in valid_node_ids and e.get('target') in valid_node_ids]

        final_graph_data = {"nodes": sanitized_nodes, "edges": sanitized_edges}
        cache_doc_ref = db_firestore.collection('users').document(user_id).collection('analysis').document('graph_cache')
        cache_doc_ref.set({'data': final_graph_data, 'updated_at': firestore.SERVER_TIMESTAMP})
        print(f"âœ… Successfully updated graph cache for user: {user_id}")
    except Exception as e:
        print(f"âŒ Failed to update graph cache for user {user_id}: {e}")
        traceback.print_exc()

# ===== èªè¨¼ãƒ˜ãƒ«ãƒ‘ãƒ¼ =====
def _verify_token(request):
    auth_header = request.headers.get('Authorization', '')
    if not auth_header.startswith('Bearer '):
        raise auth.InvalidIdTokenError("Authorization token is missing or invalid")
    id_token = auth_header.split('Bearer ')[1]
    return auth.verify_id_token(id_token, clock_skew_seconds=15)

# ===== API Routes =====
@app.route('/session/start', methods=['POST'])
def start_session():
    try:
        decoded_token = _verify_token(request)
        user_id = decoded_token['uid']
        
        data = request.get_json()
        if not data or 'topic' not in data: 
            return jsonify({'error': 'Topic is required'}), 400
        topic = data['topic']

        questions = generate_initial_questions(topic)
        if not questions: 
            raise Exception("AI failed to generate questions.")

        session_doc_ref = db_firestore.collection('users').document(user_id).collection('sessions').document()
        session_doc_ref.set({'topic': topic, 'status': 'in_progress', 'created_at': firestore.SERVER_TIMESTAMP, 'turn': 1, 'max_turns': 3})
        
        questions_collection = session_doc_ref.collection('questions')
        question_docs = []
        for i, q_data in enumerate(questions):
            if q_text := q_data.get("question_text"):
                q_doc_ref = questions_collection.document()
                q_doc_ref.set({'text': q_text, 'order': i, 'turn': 1})
                question_docs.append({'question_id': q_doc_ref.id, 'question_text': q_text})
        
        if not question_docs: 
            raise Exception("All generated questions were empty.")
        
        return jsonify({'session_id': session_doc_ref.id, 'questions': question_docs}), 200
    except (auth.InvalidIdTokenError, IndexError, ValueError) as e:
        print(f"Auth Error in start_session: {e}")
        return jsonify({'error': 'Invalid or expired token', 'details': str(e)}), 403
    except Exception as e:
        print(f"Error in start_session: {e}")
        traceback.print_exc()
        return jsonify({'error': 'Failed to start session', 'details': str(e)}), 500

@app.route('/session/<string:session_id>/swipe', methods=['POST'])
def record_swipe(session_id):
    try:
        decoded_token = _verify_token(request)
        user_id = decoded_token['uid']
        
        data = request.get_json()
        if not data: return jsonify({'error': 'Request body is missing'}), 400

        question_id = data.get('question_id')
        answer = data.get('answer') 
        hesitation_time = data.get('hesitation_time')
        speed = data.get('speed')
        turn = data.get('turn')

        if not all([question_id, turn is not None]) or not isinstance(answer, bool):
            return jsonify({'error': 'Missing or invalid type for required fields in swipe data'}), 400

        session_doc_ref = db_firestore.collection('users').document(user_id).collection('sessions').document(session_id)
        
        session_doc_ref.collection('swipes').add({
            'question_id': question_id,
            'answer': answer,
            'hesitation_time_sec': hesitation_time,
            'swipe_duration_ms': speed,
            'turn': turn,
            'timestamp': firestore.SERVER_TIMESTAMP
        })
        
        return jsonify({'status': 'swipe_recorded'}), 200
    except (auth.InvalidIdTokenError, IndexError, ValueError) as e:
        print(f"Auth Error in record_swipe: {e}")
        return jsonify({'error': 'Invalid or expired token', 'details': str(e)}), 403
    except Exception as e:
        print(f"Error recording swipe: {e}")
        traceback.print_exc()
        return jsonify({'error': 'Failed to record swipe', 'details': str(e)}), 500


# ã€å…¨é¢æ”¹ä¿®ã€‘ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ãªã„ã‚ˆã†ã«ã€é‡ã„å‡¦ç†ã‚’å…¨ã¦ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã«ç§»å‹•
@app.route('/session/<string:session_id>/summary', methods=['POST'])
def post_summary(session_id):
    try:
        decoded_token = _verify_token(request)
        user_id = decoded_token['uid']
        data = request.get_json()
        if not data or 'swipes' not in data: return jsonify({'error': 'Swipes data is required'}), 400
        
        session_doc_ref = db_firestore.collection('users').document(user_id).collection('sessions').document(session_id)
        session_doc = session_doc_ref.get()
        if not session_doc.exists: return jsonify({'error': 'Session not found'}), 404
        
        session_data = session_doc.to_dict()
        topic = session_data.get('topic', 'ä¸æ˜')
        current_turn = session_data.get('turn', 1)
        max_turns = session_data.get('max_turns', 3)
        
        swipes_text = "\n".join([f"Q: {s.get('question_text')}\nA: {'ã¯ã„' if s.get('answer') else 'ã„ã„ãˆ'}" for s in data['swipes']])

        # 1. è¦ç´„ã®ã¿ã‚’é«˜é€Ÿã«ç”Ÿæˆ
        summary_data = generate_summary_only(topic, swipes_text)
        insights_md = summary_data.get('insights')
        title = summary_data.get('title')
        if not insights_md or not title: raise Exception("AI failed to generate summary or title.")

        # 2. è¦ç´„ã‚’DBã«ä¿å­˜
        session_doc_ref.collection('analyses').add({'turn': current_turn, 'insights': insights_md, 'created_at': firestore.SERVER_TIMESTAMP})
        update_data = {'status': 'completed', 'updated_at': firestore.SERVER_TIMESTAMP, 'latest_insights': insights_md}
        if current_turn == 1: update_data['title'] = title
        session_doc_ref.update(update_data)

        # 3. é‡ã„å‡¦ç†ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§é–‹å§‹
        threading.Thread(target=_update_graph_cache, args=(user_id,)).start()
        threading.Thread(target=_prefetch_questions_and_save, args=(session_id, user_id, insights_md, current_turn, max_turns)).start()
        print("--- Started background threads for graph cache and question prefetch. ---")
        
        # 4. ã™ãã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
        return jsonify({'title': title, 'insights': insights_md, 'turn': current_turn, 'max_turns': max_turns}), 200

    except Exception as e:
        print(f"Error in post_summary: {e}")
        return jsonify({'error': 'Failed to generate summary', 'details': str(e)}), 500

@app.route('/session/<string:session_id>/continue', methods=['POST'])
def continue_session(session_id):
    try:
        decoded_token = _verify_token(request)
        user_id = decoded_token['uid']
        
        session_doc_ref = db_firestore.collection('users').document(user_id).collection('sessions').document(session_id)
        
        @firestore.transactional
        def update_turn(transaction, ref):
            snapshot = ref.get(transaction=transaction)
            if not snapshot.exists: raise Exception("Session not found")
            data = snapshot.to_dict()
            if data.get('turn', 1) >= data.get('max_turns', 3): raise Exception("Max turns reached.")
            new_turn = data.get('turn', 1) + 1
            transaction.update(ref, {'status': 'in_progress', 'turn': new_turn, 'updated_at': firestore.SERVER_TIMESTAMP})
            return new_turn
        
        transaction = db_firestore.transaction()
        new_turn = update_turn(transaction, session_doc_ref)

        questions_collection = session_doc_ref.collection('questions')
        query = questions_collection.where('turn', '==', new_turn).order_by('order')
        question_docs = [{'question_id': doc.id, 'question_text': doc.to_dict().get('text')} for doc in query.stream()]

        if not question_docs:
            print(f"âš ï¸ Prefetched questions not found for turn {new_turn}. Generating and SAVING now (fallback).")
            last_analysis_doc = next(session_doc_ref.collection('analyses').order_by('created_at', direction=firestore.Query.DESCENDING).limit(1).stream(), None)
            if not last_analysis_doc: raise Exception("Cannot generate fallback questions: no analysis found.")
            
            fallback_questions = generate_follow_up_questions(last_analysis_doc.to_dict().get('insights'))
            if not fallback_questions: raise Exception("AI failed to generate fallback questions.")

            # --- ã“ã“ã‹ã‚‰ãŒä¿®æ­£ã®æ ¸å¿ƒéƒ¨åˆ†ã§ã™ ---
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ç”Ÿæˆã—ãŸè³ªå•ã‚‚ã€å¿…ãšDBã«ä¿å­˜ã—ã¦ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è¿”ã™
            last_question_query = questions_collection.order_by('order', direction=firestore.Query.DESCENDING).limit(1).stream()
            last_order = next(last_question_query, None)
            start_order = last_order.to_dict().get('order', -1) + 1 if last_order else 0

            batch = db_firestore.batch()
            for i, q_data in enumerate(fallback_questions):
                if q_text := q_data.get("question_text"):
                    # DBã«ä¿å­˜ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDã‚’ä½œæˆ
                    q_doc_ref = questions_collection.document()
                    batch.set(q_doc_ref, {
                        'text': q_text,
                        'turn': new_turn,
                        'order': start_order + i,
                        'created_at': firestore.SERVER_TIMESTAMP,
                        'is_prefetched': False # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ç”Ÿæˆã•ã‚ŒãŸã“ã¨ã‚’ç¤ºã™
                    })
                    # DBã«ä¿å­˜ã™ã‚‹IDã¨åŒã˜IDã‚’ä½¿ã£ã¦ã€ãƒ•ãƒ­ãƒ³ãƒˆã«è¿”ã™ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
                    question_docs.append({
                        'question_id': q_doc_ref.id,
                        'question_text': q_text
                    })
            batch.commit() # DBã¸ã®ä¿å­˜ã‚’ç¢ºå®š
            print(f"âœ… Saved {len(fallback_questions)} fallback questions to Firestore.")
            # --- ä¿®æ­£ã®æ ¸å¿ƒéƒ¨åˆ†ã“ã“ã¾ã§ ---
        
        if not question_docs: raise Exception("Failed to get any questions for the user.")
        return jsonify({'session_id': session_id, 'questions': question_docs, 'turn': new_turn}), 200
    except Exception as e:
        print(f"Error in continue_session: {e}")
        traceback.print_exc()
        return jsonify({'error': 'Failed to continue session', 'details': str(e)}), 500

# --- åˆ†æç³»API ---

def _get_all_insights_as_text(user_id: str) -> str:
    if not db_firestore: return ""
    sessions_ref = db_firestore.collection('users').document(user_id).collection('sessions').order_by('created_at').limit_to_last(20)
    
    # â˜…â˜…â˜… ä¿®æ­£ç‚¹2: .stream() ã‚’ .get() ã«å¤‰æ›´ â˜…â˜…â˜…
    sessions = sessions_ref.get() 

    all_insights = []
    for session in sessions:
        try:
            session_data = session.to_dict()
            if not session_data: continue

            topic = str(session_data.get('topic', ''))
            title = str(session_data.get('title', ''))
            all_insights.append(f"--- ã‚»ãƒƒã‚·ãƒ§ãƒ³: {topic} ({title}) ---\n")

            analyses_ref = session.reference.collection('analyses').order_by('created_at')
            for analysis in analyses_ref.stream():
                analysis_data = analysis.to_dict()
                if analysis_data and isinstance(analysis_data.get('insights'), str):
                    all_insights.append(analysis_data['insights'] + "\n")
        except Exception as inner_e:
            print(f"Skipping potentially corrupted session {session.id} for insight aggregation due to error: {inner_e}")
            continue
    
    return "".join(all_insights)

@app.route('/analysis/chat', methods=['POST'])
def post_chat_message():
    try:
        decoded_token = _verify_token(request)
        user_id = decoded_token['uid']
        data = request.get_json()
        if not data or not (user_message := data.get('message')): return jsonify({'error': 'message is required'}), 400
        
        session_summary = _get_all_insights_as_text(user_id)
        if not session_summary:
            ai_response = "ã“ã‚“ã«ã¡ã¯ã€‚åˆ†æã§ãã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ãŒã¾ã ãªã„ã‚ˆã†ã§ã™ã€‚ã¾ãšã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å®Œäº†ã—ã¦ã€ã”è‡ªèº«ã®å†…é¢ã‚’æ¢ã‚‹æ—…ã‚’å§‹ã‚ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
        else:
            ai_response = generate_chat_response(session_summary, data.get('chat_history', []), user_message)
        return jsonify({'response': ai_response})
    except Exception as e:
        print(f"Error in post_chat_message: {e}")
        return jsonify({"error": "An internal error occurred."}), 500

@app.route('/analysis/graph', methods=['GET'])
def get_analysis_graph():
    try:
        decoded_token = _verify_token(request)
        user_id = decoded_token['uid']
        cache_doc_ref = db_firestore.collection('users').document(user_id).collection('analysis').document('graph_cache')
        cache_doc = cache_doc_ref.get()
        if cache_doc.exists:
            return jsonify(cache_doc.to_dict().get('data', {"nodes": [], "edges": []}))
        else:
            print(f"--- No graph cache for user: {user_id}. Returning empty and triggering update. ---")
            threading.Thread(target=_update_graph_cache, args=(user_id,)).start()
            return jsonify({"nodes": [], "edges": []})
    except Exception as e:
        print(f"Error in get_analysis_graph: {e}")
        return jsonify({"error": "An internal error occurred."}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080, debug=True)